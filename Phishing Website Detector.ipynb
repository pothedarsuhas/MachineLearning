{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions:\n",
      " [ 1 -1 -1 ... -1 -1  1]\n",
      "accuracy of KNN:  0.9529695507989147\n",
      "misclassfied elements\n",
      "(array([   4,   24,   98,  106,  130,  158,  201,  204,  206,  222,  238,\n",
      "        252,  305,  308,  317,  328,  347,  352,  370,  406,  469,  503,\n",
      "        509,  515,  518,  526,  536,  607,  634,  636,  649,  665,  667,\n",
      "        702,  719,  722,  725,  813,  827,  871,  893,  896,  944,  947,\n",
      "        988, 1021, 1023, 1041, 1045, 1046, 1057, 1058, 1081, 1110, 1132,\n",
      "       1155, 1157, 1189, 1201, 1203, 1238, 1252, 1274, 1279, 1307, 1330,\n",
      "       1399, 1402, 1419, 1466, 1467, 1477, 1483, 1544, 1545, 1557, 1562,\n",
      "       1571, 1609, 1622, 1661, 1671, 1712, 1721, 1747, 1752, 1754, 1755,\n",
      "       1778, 1787, 1810, 1840, 1854, 1883, 1940, 1941, 1948, 2037, 2082,\n",
      "       2138, 2140, 2162, 2216, 2266, 2276, 2338, 2339, 2361, 2381, 2385,\n",
      "       2391, 2393, 2449, 2478, 2507, 2526, 2534, 2585, 2630, 2631, 2635,\n",
      "       2706, 2740, 2760, 2776, 2782, 2803, 2808, 2817, 2822, 2826, 2828,\n",
      "       2856, 2857, 2863, 2894, 2912, 2926, 2928, 2937, 2950, 2967, 2996,\n",
      "       3041, 3060, 3066, 3094, 3103, 3126, 3136, 3162, 3199, 3231, 3235,\n",
      "       3298, 3310]),)\n",
      "misclassfied elements count:  156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Dict of accuracies\n",
    "d = {}\n",
    "\n",
    "p = pd.read_csv(\"phishing.csv\")\n",
    "#p.info()\n",
    "#print(type(p))\n",
    "\n",
    "p.columns = ['having_IPhaving_IP_Address',\n",
    "'URLURL_Length',\n",
    "'Shortining_Service',\n",
    "'having_At_Symbol',\n",
    "'double_slash_redirecting',\n",
    "'Prefix_Suffix',\n",
    "'having_Sub_Domain',\n",
    "'SSLfinal_State',\n",
    "'Domain_registeration_length',\n",
    "'Favicon',\n",
    "'port',\n",
    "'HTTPS_token',\n",
    "'Request_URL',\n",
    "'URL_of_Anchor',\n",
    "'Links_in_tags',\n",
    "'SFH',\n",
    "'Submitting_to_email',\n",
    "'Abnormal_URL',\n",
    "'Redirect',\n",
    "'on_mouseover',\n",
    "'RightClick',\n",
    "'popUpWidnow',\n",
    "'Iframe',\n",
    "'age_of_domain',\n",
    "'DNSRecord',\n",
    "'web_traffic',\n",
    "'Page_Rank',\n",
    "'Google_Index',\n",
    "'Links_pointing_to_page',\n",
    "'Statistical_report',\n",
    "'Result']\n",
    "\n",
    "\n",
    "target = p[\"Result\"].T\n",
    "\n",
    "data = p.drop('Result', axis = 1)\n",
    "#KNN classification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(data, target, test_size=0.3,random_state=21, stratify=target)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))\n",
    "print(\"accuracy of KNN: \",knn.score(X_test, y_test))\n",
    "\n",
    "d['accuracy of KNN'] = knn.score(X_test, y_test)\n",
    "\n",
    "#len(X_test)\n",
    "\n",
    "y_test = np.asarray(y_test)\n",
    "X_test = np.asarray(X_test)\n",
    "\n",
    "misclassified = np.where(y_test != y_pred)\n",
    "print(\"misclassfied elements\")\n",
    "print(misclassified)\n",
    "print(\"misclassfied elements count: \", len(misclassified[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of DT: 0.967741935483871\n",
      "misclassfied elements\n",
      "(array([   6,   41,   53,   99,  114,  158,  201,  206,  237,  252,  257,\n",
      "        317,  328,  406,  434,  451,  518,  521,  661,  665,  667,  677,\n",
      "        722,  725,  779,  831,  944,  972,  986,  999, 1016, 1021, 1046,\n",
      "       1057, 1074, 1081, 1084, 1155, 1189, 1201, 1255, 1279, 1287, 1301,\n",
      "       1355, 1434, 1467, 1483, 1544, 1545, 1553, 1702, 1712, 1715, 1721,\n",
      "       1747, 1752, 1754, 1763, 1810, 1814, 1840, 1842, 1953, 1984, 1998,\n",
      "       2004, 2077, 2083, 2124, 2145, 2205, 2208, 2266, 2361, 2373, 2381,\n",
      "       2385, 2386, 2393, 2431, 2449, 2464, 2534, 2535, 2552, 2571, 2585,\n",
      "       2631, 2633, 2667, 2776, 2822, 2866, 2894, 2937, 2967, 3041, 3049,\n",
      "       3066, 3090, 3094, 3136, 3162, 3199, 3298, 3313]),)\n"
     ]
    }
   ],
   "source": [
    "##Decision Trees\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
    "dt = DecisionTreeClassifier(max_depth=25, random_state=1)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Compute test set accuracy  \n",
    "acc = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"accuracy of DT: {}\".format(acc))\n",
    "\n",
    "d['accuracy of DT'] = acc\n",
    "\n",
    "misclassified = np.where(y_test != y_pred_dt)\n",
    "print(\"misclassfied elements\")\n",
    "print(misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of DT Bagging: 0.9740729574917094, OOB accuracy: 0.9648442548791522\n",
      "misclassfied elements\n",
      "(array([   1,   99,  114,  158,  201,  206,  240,  252,  257,  317,  328,\n",
      "        406,  451,  482,  484,  503,  509,  518,  591,  649,  665,  667,\n",
      "        722,  725,  742,  831,  944,  947,  972,  986,  999, 1021, 1027,\n",
      "       1046, 1057, 1081, 1155, 1189, 1201, 1279, 1434, 1436, 1467, 1482,\n",
      "       1483, 1544, 1545, 1546, 1712, 1747, 1752, 1754, 1810, 1998, 2083,\n",
      "       2124, 2138, 2145, 2266, 2361, 2381, 2385, 2393, 2449, 2534, 2571,\n",
      "       2585, 2607, 2631, 2657, 2776, 2822, 2850, 2894, 2937, 2950, 2967,\n",
      "       2996, 3013, 3066, 3136, 3162, 3199, 3298, 3313, 3315]),)\n",
      "misclassfied elements count:  86\n",
      "######################################\n"
     ]
    }
   ],
   "source": [
    "## Ensemble bagging\n",
    "\n",
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt_b = DecisionTreeClassifier(random_state=1, max_depth = 25)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt_b, \n",
    "                       n_estimators=50,\n",
    "                       oob_score=True,\n",
    "                       random_state=1)\n",
    "\n",
    "# Fit bc to the training set \n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred_dt_b = bc.predict(X_test)\n",
    "\n",
    "# Evaluate test set accuracy\n",
    "acc_test = accuracy_score(y_test, y_pred_dt_b)\n",
    "\n",
    "d['accuracy of Bagging DT'] = acc_test\n",
    "\n",
    "\n",
    "# Evaluate OOB accuracy\n",
    "acc_oob = bc.oob_score_\n",
    "\n",
    "d['oob accuracy of Bagging DT'] = acc_oob\n",
    "\n",
    "# Print acc_test and acc_oob\n",
    "print('accuracy of DT Bagging: {}, OOB accuracy: {}'.format(acc_test, acc_oob))\n",
    "\n",
    "misclassified = np.where(y_test != y_pred_dt_b)\n",
    "print(\"misclassfied elements\")\n",
    "print(misclassified)\n",
    "print(\"misclassfied elements count: \", len(misclassified[0]) )\n",
    "\n",
    "print(\"BEST MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbours : 0.9529695507989147\n",
      "Classification Tree : 0.967741935483871\n",
      "Voting Classifier: 0.967741935483871\n",
      "misclassfied elements\n",
      "(array([   6,   24,   41,   53,   99,  130,  158,  201,  204,  206,  222,\n",
      "        237,  238,  252,  257,  305,  317,  328,  370,  406,  434,  469,\n",
      "        509,  518,  521,  607,  661,  665,  667,  702,  719,  722,  725,\n",
      "        813,  896,  944,  972,  986,  999, 1016, 1021, 1041, 1046, 1057,\n",
      "       1074, 1081, 1084, 1132, 1155, 1189, 1201, 1252, 1274, 1279, 1287,\n",
      "       1399, 1434, 1466, 1467, 1483, 1544, 1545, 1562, 1671, 1702, 1712,\n",
      "       1715, 1721, 1747, 1752, 1754, 1810, 1840, 1842, 1854, 1883, 1941,\n",
      "       1948, 1953, 1998, 2004, 2037, 2077, 2082, 2083, 2124, 2140, 2162,\n",
      "       2205, 2216, 2266, 2276, 2339, 2361, 2381, 2385, 2393, 2449, 2464,\n",
      "       2478, 2507, 2526, 2534, 2552, 2585, 2630, 2631, 2633, 2776, 2803,\n",
      "       2808, 2822, 2826, 2828, 2856, 2857, 2866, 2894, 2926, 2937, 2967,\n",
      "       3041, 3060, 3066, 3090, 3094, 3126, 3136, 3162, 3199, 3298, 3310]),)\n",
      "misclassfied elements count:  132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "##Ensemble Voting\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "SEED = 1\n",
    "\n",
    "\n",
    "# Instantiate knn\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=SEED, max_depth = 25)\n",
    "\n",
    "\n",
    "classifiers = [ ('K Nearest Neighbours', knn), ('Classification Tree', dt)]\n",
    "for clf_name, clf in classifiers:  \n",
    "    # Fit clf to the training set\n",
    "    clf.fit(X_train, y_train)  \n",
    "    # Predict y_pred\n",
    "    y_pred = clf.predict(X_test)    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)  \n",
    "    d['accuracy of'+ ' ' + clf_name +' in Voting'] = accuracy\n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{} : {}'.format(clf_name, accuracy))\n",
    "    \n",
    "\n",
    "# Import VotingCLassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Instantiate a VotingClassifier vc \n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)   \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred_vc = vc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Voting Classifier: {}'.format(accuracy))\n",
    "\n",
    "d['accuracy of Voting classifiers collectively'] = accuracy\n",
    "\n",
    "misclassified = np.where(y_test != y_pred_vc)\n",
    "print(\"misclassfied elements\")\n",
    "print(misclassified)\n",
    "print(\"misclassfied elements count: \", len(misclassified[0]) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.8477539945734097\n",
      "misclassfied elements\n",
      "(array([   1,   12,   31,   39,   46,   51,   56,   63,   67,  106,  114,\n",
      "        118,  123,  127,  129,  132,  142,  158,  162,  166,  168,  185,\n",
      "        201,  203,  207,  227,  232,  236,  240,  252,  254,  258,  261,\n",
      "        288,  294,  308,  312,  328,  343,  347,  361,  375,  379,  383,\n",
      "        384,  411,  413,  426,  435,  444,  451,  453,  460,  466,  474,\n",
      "        482,  484,  490,  500,  503,  516,  518,  524,  525,  526,  536,\n",
      "        538,  540,  541,  550,  558,  561,  565,  568,  576,  578,  581,\n",
      "        591,  594,  599,  603,  614,  624,  631,  634,  649,  652,  653,\n",
      "        665,  671,  672,  677,  683,  685,  689,  713,  716,  722,  742,\n",
      "        757,  758,  761,  765,  767,  774,  777,  779,  781,  787,  791,\n",
      "        795,  796,  812,  814,  826,  827,  828,  831,  843,  845,  851,\n",
      "        852,  854,  855,  863,  870,  884,  885,  886,  889,  899,  905,\n",
      "        934,  940,  944,  947,  948,  953,  957,  967,  970,  971,  980,\n",
      "        982,  993,  994, 1005, 1021, 1023, 1027, 1035, 1045, 1046, 1048,\n",
      "       1053, 1057, 1060, 1062, 1071, 1081, 1090, 1110, 1111, 1114, 1124,\n",
      "       1127, 1133, 1137, 1151, 1155, 1159, 1160, 1161, 1166, 1177, 1178,\n",
      "       1189, 1196, 1200, 1201, 1203, 1206, 1212, 1223, 1225, 1238, 1248,\n",
      "       1250, 1255, 1257, 1264, 1270, 1279, 1292, 1298, 1301, 1302, 1307,\n",
      "       1322, 1330, 1337, 1343, 1355, 1376, 1383, 1388, 1424, 1436, 1437,\n",
      "       1443, 1445, 1467, 1477, 1481, 1482, 1483, 1494, 1501, 1523, 1539,\n",
      "       1544, 1545, 1546, 1547, 1551, 1553, 1557, 1575, 1579, 1587, 1600,\n",
      "       1603, 1609, 1612, 1622, 1636, 1639, 1646, 1661, 1666, 1697, 1706,\n",
      "       1712, 1720, 1722, 1725, 1728, 1731, 1733, 1740, 1743, 1744, 1747,\n",
      "       1750, 1752, 1754, 1755, 1763, 1764, 1771, 1778, 1782, 1787, 1790,\n",
      "       1802, 1803, 1806, 1814, 1816, 1819, 1829, 1830, 1832, 1835, 1841,\n",
      "       1847, 1856, 1860, 1863, 1867, 1877, 1891, 1893, 1894, 1897, 1904,\n",
      "       1906, 1907, 1911, 1912, 1919, 1923, 1925, 1932, 1937, 1940, 1951,\n",
      "       1959, 1968, 1971, 1982, 1984, 1988, 2003, 2005, 2017, 2018, 2019,\n",
      "       2056, 2066, 2067, 2072, 2076, 2090, 2101, 2108, 2125, 2133, 2138,\n",
      "       2145, 2149, 2161, 2164, 2189, 2190, 2192, 2208, 2218, 2230, 2233,\n",
      "       2246, 2247, 2259, 2261, 2264, 2269, 2277, 2278, 2282, 2287, 2297,\n",
      "       2305, 2323, 2324, 2338, 2349, 2350, 2353, 2357, 2358, 2360, 2362,\n",
      "       2373, 2381, 2386, 2387, 2394, 2397, 2402, 2408, 2429, 2431, 2449,\n",
      "       2450, 2467, 2472, 2474, 2480, 2486, 2492, 2501, 2502, 2508, 2510,\n",
      "       2512, 2513, 2534, 2535, 2537, 2544, 2547, 2554, 2564, 2567, 2568,\n",
      "       2571, 2576, 2577, 2584, 2587, 2593, 2597, 2607, 2631, 2635, 2657,\n",
      "       2667, 2668, 2674, 2681, 2684, 2688, 2697, 2706, 2708, 2714, 2717,\n",
      "       2722, 2732, 2738, 2749, 2752, 2754, 2757, 2760, 2768, 2773, 2774,\n",
      "       2775, 2776, 2782, 2789, 2793, 2795, 2797, 2801, 2817, 2819, 2821,\n",
      "       2827, 2833, 2841, 2848, 2849, 2850, 2851, 2863, 2868, 2874, 2876,\n",
      "       2889, 2897, 2898, 2899, 2901, 2908, 2912, 2920, 2925, 2928, 2945,\n",
      "       2949, 2950, 2954, 2956, 2963, 2967, 2975, 2981, 2983, 2985, 2995,\n",
      "       2996, 3000, 3013, 3018, 3036, 3039, 3049, 3053, 3054, 3066, 3099,\n",
      "       3110, 3113, 3131, 3136, 3142, 3148, 3162, 3163, 3165, 3173, 3177,\n",
      "       3181, 3189, 3198, 3208, 3210, 3212, 3213, 3228, 3234, 3235, 3238,\n",
      "       3250, 3254, 3264, 3283, 3286, 3290, 3302, 3313, 3314, 3315]),)\n",
      "misclassfied elements count:  505\n"
     ]
    }
   ],
   "source": [
    "##Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "target = p[\"Result\"].T\n",
    "\n",
    "data = p[['Prefix_Suffix','URL_of_Anchor']].values\n",
    "#print(data)\n",
    "#print(target)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(data, target, test_size=0.3,random_state=21, stratify=target)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(C = 100)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred_LoR = logreg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_LoR)\n",
    "print('Logistic Regression: {}'.format(accuracy))\n",
    "\n",
    "d['accuracy of Logistic Regression'] = accuracy\n",
    "\n",
    "misclassified = np.where(y_test != y_pred_LoR)\n",
    "print(\"misclassfied elements\")\n",
    "print(misclassified)\n",
    "print(\"misclassfied elements count: \", len(misclassified[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "accuracy of KNN  :  0.9529695507989147\n",
      "accuracy of DT  :  0.967741935483871\n",
      "accuracy of Bagging DT  :  0.9740729574917094\n",
      "oob accuracy of Bagging DT  :  0.9648442548791522\n",
      "accuracy of K Nearest Neighbours in Voting  :  0.9529695507989147\n",
      "accuracy of Classification Tree in Voting  :  0.967741935483871\n",
      "accuracy of Voting classifiers collectively  :  0.967741935483871\n",
      "accuracy of Logistic Regression  :  0.8477539945734097\n"
     ]
    }
   ],
   "source": [
    "print('\\n')\n",
    "print('\\n')\n",
    "for i in d:\n",
    "    print(i,' : ' ,d[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
